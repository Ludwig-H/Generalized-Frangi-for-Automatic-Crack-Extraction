{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "385e2317",
      "metadata": {
        "id": "385e2317"
      },
      "source": [
        "\n",
        "# Generalized Frangi with Multi-modal Fusion for Crack Extraction, tested on FIND benchmark\n",
        "\n",
        "This Colab notebook demonstrates the complete pipeline (download, unzip, Hessians, fusion, Frangi graph, HDBSCAN, MST + k-centers, animation, and metrics).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f8a070ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8a070ef",
        "outputId": "31b94a3f-9dff-4084-b2aa-64ddda5f3133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install deps\n",
        "!pip -q install numpy scipy scikit-image matplotlib joblib tqdm tqdm-joblib hdbscan networkx gdown pot imageio pandas Pillow tqdm_joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Ludwig-H/Generalized-Frangi-for-Automatic-Crack-Extraction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTYtC3K3XoqL",
        "outputId": "1cb0c0ea-7126-4b7a-c17a-976244165379"
      },
      "id": "hTYtC3K3XoqL",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Generalized-Frangi-for-Automatic-Crack-Extraction'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 90 (delta 37), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (90/90), 1.51 MiB | 6.82 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "04ad0934",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "04ad0934",
        "outputId": "b6741fbf-5470-40e6-c7e4-e6c293dd85da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tqdm_joblib/__init__.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (utils_bis.py, line 59)",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"/tmp/ipython-input-1825168850.py\"\u001b[0m, line \u001b[1;32m13\u001b[0m, in \u001b[1;35m<cell line: 0>\u001b[0m\n    from frangi_fusion import (set_seed, auto_discover_find_structure, load_modalities_and_gt_by_index,\n",
            "\u001b[0;36m  File \u001b[0;32m\"/content/Generalized-Frangi-for-Automatic-Crack-Extraction/src/frangi_fusion/__init__.py\"\u001b[0;36m, line \u001b[0;32m10\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from .utils_bis import _read_image_any, to_gray_uint8, _to_gray_float01, _is_image_file, _extract_key, auto_discover_find_structure, load_modalities_and_gt_by_index\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"/content/Generalized-Frangi-for-Automatic-Crack-Extraction/src/frangi_fusion/utils_bis.py\"\u001b[0;36m, line \u001b[0;32m59\u001b[0m\n\u001b[0;31m    import .utils as U\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import os, sys, glob, re, random, numpy as np, imageio, matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from tqdm_joblib import tqdm_joblib\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Allow importing from this repo if running in Colab after uploading or mounting\n",
        "repo_path = os.path.abspath(\"Generalized-Frangi-for-Automatic-Crack-Extraction\")\n",
        "src_path = os.path.join(repo_path, \"src\")\n",
        "if src_path not in sys.path:\n",
        "    sys.path.append(src_path)\n",
        "\n",
        "\n",
        "from frangi_fusion import (set_seed, auto_discover_find_structure, load_modalities_and_gt_by_index,\n",
        "                           to_gray, compute_hessians_per_scale, fuse_hessians_per_scale,\n",
        "                           build_frangi_similarity_graph, distances_from_similarity, triangle_connectivity_graph,\n",
        "                           largest_connected_component, hdbscan_from_sparse,\n",
        "                           mst_on_cluster, kcenters_on_tree, fault_graph_from_mst_and_kcenters,\n",
        "                           skeletonize_lee, jaccard_index, tversky_index, wasserstein_distance_skeletons, thicken,\n",
        "                           overlay_hessian_orientation, show_clusters_on_image, animate_fault_growth)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c3d3577",
      "metadata": {
        "id": "8c3d3577"
      },
      "source": [
        "## 1) Download FIND `data.zip` and unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2cceeff",
      "metadata": {
        "id": "f2cceeff"
      },
      "outputs": [],
      "source": [
        "\n",
        "import gdown, zipfile\n",
        "url = \"https://drive.google.com/uc?id=1qnLMCeon7LJjT9H0ENiNF5sFs-F7-NvK\"\n",
        "zip_path = \"data.zip\"\n",
        "if not os.path.exists(zip_path):\n",
        "    gdown.download(url, zip_path, quiet=False)\n",
        "\n",
        "extract_dir = \"data_find\"\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    zf.extractall(extract_dir)\n",
        "print(\"Unzipped to:\", extract_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e502500",
      "metadata": {
        "id": "1e502500"
      },
      "source": [
        "## 2) Pick one image and display modalities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ensure your src/ is on path if you import from the repo\n",
        "if \"src\" not in \"\".join(sys.path):\n",
        "    sys.path.append(\"/content/icpr2026-frangi-fusion-find/src\")  # ajuste selon ton arbo\n"
      ],
      "metadata": {
        "id": "lIx3f0aMT7jI"
      },
      "id": "lIx3f0aMT7jI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FIX for FIND fused TIFFs and robust grayscale conversion ---\n",
        "\n",
        "%pip -q install tifffile imageio scikit-image\n",
        "\n",
        "import numpy as np, re, random\n",
        "import imageio.v2 as iio\n",
        "from skimage.io import imread as ski_imread\n",
        "from importlib import reload\n",
        "import sys, os\n",
        "\n",
        "# ensure your src/ is on path if you import from the repo\n",
        "if \"src\" not in \"\".join(sys.path):\n",
        "    sys.path.append(\"/content/icpr2026-frangi-fusion-find/src\")  # ajuste selon ton arbo\n",
        "\n",
        "# # ---------- robust readers / grayscale ----------\n",
        "# def _read_image_any(path):\n",
        "#     # 1) PIL\n",
        "#     try:\n",
        "#         from PIL import Image\n",
        "#         with Image.open(path) as im:\n",
        "#             arr = np.array(im)\n",
        "#             if arr.ndim == 3 and arr.shape[2] == 4:\n",
        "#                 arr = arr[..., :3]\n",
        "#             return arr\n",
        "#     except Exception:\n",
        "#         pass\n",
        "#     # 2) imageio\n",
        "#     try:\n",
        "#         arr = iio.imread(path)\n",
        "#         if arr.ndim == 3 and arr.shape[2] == 4:\n",
        "#             arr = arr[..., :3]\n",
        "#         return arr\n",
        "#     except Exception:\n",
        "#         pass\n",
        "#     # 3) skimage (tifffile backend)\n",
        "#     try:\n",
        "#         arr = ski_imread(path)\n",
        "#         if arr.ndim == 3 and arr.shape[2] == 4:\n",
        "#             arr = arr[..., :3]\n",
        "#         return arr\n",
        "#     except Exception as e:\n",
        "#         raise e\n",
        "\n",
        "# def to_gray_uint8(img):\n",
        "#     # Accept HxW or HxWxC (any C>=1). For C>=3 use luminance on first 3, C==2 average.\n",
        "#     if img.ndim == 2:\n",
        "#         g = img.astype(np.float32)\n",
        "#     elif img.ndim == 3:\n",
        "#         c = img.shape[2]\n",
        "#         arr = img.astype(np.float32)\n",
        "#         if c >= 3:\n",
        "#             w = np.array([0.2989, 0.5870, 0.1140], dtype=np.float32)\n",
        "#             g = arr[..., :3].dot(w)\n",
        "#         elif c == 2:\n",
        "#             g = arr.mean(axis=2)\n",
        "#         else:  # C==1 or weird\n",
        "#             g = arr[..., 0]\n",
        "#     else:\n",
        "#         raise ValueError(\"Unsupported image shape\")\n",
        "#     g -= g.min()\n",
        "#     if g.max() > 0:\n",
        "#         g /= g.max()\n",
        "#     return (g * 255).clip(0,255).astype(np.uint8)\n",
        "\n",
        "# # ---------- monkey-patch repo utilities if present ----------\n",
        "# try:\n",
        "#     import frangi_fusion.utils as U\n",
        "#     import frangi_fusion.hessian as H\n",
        "#     # patch readers / grayscale\n",
        "#     U._read_image = _read_image_any\n",
        "#     U.to_gray_uint8 = to_gray_uint8\n",
        "\n",
        "#     def _to_gray_float01(img):\n",
        "#         g = to_gray_uint8(img).astype(np.float32) / 255.0\n",
        "#         return g\n",
        "#     H.to_gray = _to_gray_float01\n",
        "#     reload(U); reload(H)\n",
        "# except Exception as _e:\n",
        "#     print(\"Patch local only (no package found). Proceeding with helper fns in notebook.\")\n",
        "\n",
        "# # ---------- optional: safer loader that skips broken modalities ----------\n",
        "# import os, glob\n",
        "\n",
        "# def _is_image_file(p):\n",
        "#     return p.lower().endswith((\".png\",\".jpg\",\".jpeg\",\".tif\",\".tiff\",\"bmp\"))\n",
        "\n",
        "# def _extract_key(p):\n",
        "#     m = re.findall(r\"\\d+\", os.path.basename(p))\n",
        "#     return m[-1] if m else os.path.basename(p)\n",
        "\n",
        "# def auto_discover_find_structure(root):\n",
        "#     all_imgs = [p for p in glob.glob(os.path.join(root, '**', '*.*'), recursive=True) if _is_image_file(p)]\n",
        "#     buckets = {'intensity': [], 'range': [], 'fused': [], 'label': []}\n",
        "#     for p in all_imgs:\n",
        "#         low = p.lower().replace('\\\\','/')\n",
        "#         if any(k in low for k in ['label','labels','gt','groundtruth','ground_truth','mask']):\n",
        "#             buckets['label'].append(p)\n",
        "#         elif any(k in low for k in ['fused','fusion']):\n",
        "#             buckets['fused'].append(p)\n",
        "#         elif any(k in low for k in ['range','depth']):\n",
        "#             buckets['range'].append(p)\n",
        "#         elif any(k in low for k in ['intensity','gray','grayscale']):\n",
        "#             buckets['intensity'].append(p)\n",
        "#         else:\n",
        "#             buckets['intensity'].append(p)\n",
        "#     for k in buckets: buckets[k] = sorted(buckets[k])\n",
        "#     return buckets\n",
        "\n",
        "# def load_modalities_and_gt_by_index(struct, index):\n",
        "#     base_list = struct['label'] if struct['label'] else struct['intensity']\n",
        "#     assert base_list, \"No images found in FIND root.\"\n",
        "#     index = index % len(base_list)\n",
        "#     key = _extract_key(base_list[index])\n",
        "#     out = {'paths':{}, 'arrays':{}}\n",
        "#     for k in ['intensity','range','fused','label']:\n",
        "#         cand = [p for p in struct.get(k,[]) if _extract_key(p)==key]\n",
        "#         if not cand:\n",
        "#             continue\n",
        "#         pth = cand[0]\n",
        "#         try:\n",
        "#             arr = _read_image_any(pth)\n",
        "#             out['paths'][k] = pth\n",
        "#             if k == 'label':\n",
        "#                 g = to_gray_uint8(arr)\n",
        "#                 out['arrays'][k] = (g > 127).astype(np.uint8) * 255\n",
        "#             else:\n",
        "#                 out['arrays'][k] = to_gray_uint8(arr)\n",
        "#         except Exception as e:\n",
        "#             # skip unreadable modality\n",
        "#             print(f\"[WARN] Skipping unreadable {k}: {pth} ({e})\")\n",
        "#             continue\n",
        "#     return out\n"
      ],
      "metadata": {
        "id": "pshNieFKZ-m_"
      },
      "id": "pshNieFKZ-m_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49535200",
      "metadata": {
        "id": "49535200"
      },
      "outputs": [],
      "source": [
        "\n",
        "set_seed(123)\n",
        "struct = auto_discover_find_structure(extract_dir)\n",
        "n_total = len(struct[\"label\"]) if struct[\"label\"] else len(struct[\"intensity\"])\n",
        "index = random.randint(0, max(0,n_total-1))\n",
        "dat = load_modalities_and_gt_by_index(struct, index)\n",
        "print(\"Selected index:\", index)\n",
        "for k,v in dat[\"paths\"].items():\n",
        "    print(k, \"->\", v)\n",
        "\n",
        "cols = len(dat[\"arrays\"])\n",
        "plt.figure(figsize=(4*cols,4))\n",
        "for i,(k,arr) in enumerate(dat[\"arrays\"].items()):\n",
        "    plt.subplot(1, cols, i+1); plt.title(k); plt.imshow(arr, cmap='gray'); plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e9edaa7",
      "metadata": {
        "id": "2e9edaa7"
      },
      "source": [
        "## 3) Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c58450",
      "metadata": {
        "id": "c0c58450"
      },
      "outputs": [],
      "source": [
        "\n",
        "sigmas = [5]\n",
        "beta = 0.5\n",
        "c = 0.25\n",
        "ctheta = 0.125\n",
        "R = 5\n",
        "K = 1\n",
        "expZ = 2.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba012b28",
      "metadata": {
        "id": "ba012b28"
      },
      "source": [
        "## 4–5) Hessians and fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9297205",
      "metadata": {
        "id": "b9297205"
      },
      "outputs": [],
      "source": [
        "mods = {}\n",
        "if \"intensity\" in dat[\"arrays\"]:\n",
        "    mods[\"intensity\"] = compute_hessians_per_scale(to_gray(dat[\"arrays\"][\"intensity\"]), sigmas)\n",
        "if \"range\" in dat[\"arrays\"]:\n",
        "    mods[\"range\"] = compute_hessians_per_scale(to_gray(dat[\"arrays\"][\"range\"]), sigmas)\n",
        "# if \"fused\" in dat[\"arrays\"]:\n",
        "#     mods[\"fused\"] = compute_hessians_per_scale(to_gray(dat[\"arrays\"][\"fused\"]), sigmas)\n",
        "\n",
        "weights = {k:1/len(mods.keys()) for k in mods.keys()}\n",
        "fused_H = fuse_hessians_per_scale(mods, weights)\n",
        "print(\"Fused using modalities:\", list(mods.keys()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bd81111",
      "metadata": {
        "id": "2bd81111"
      },
      "source": [
        "## 6) Visualize Hessian overlays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8743320f",
      "metadata": {
        "id": "8743320f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# base = dat[\"arrays\"].get(\"intensity\", list(dat[\"arrays\"].values())[0])\n",
        "# plt.figure(figsize=(15,4))\n",
        "# for i, Hd in enumerate(fused_H[:4]):\n",
        "#     overlay = overlay_hessian_orientation(base, Hd, alpha=0.5)\n",
        "#     plt.subplot(1,4,i+1); plt.title(f\"Sigma={Hd['sigma']}\"); plt.imshow(overlay); plt.axis('off')\n",
        "# plt.show()\n",
        "\n",
        "# Overlays avec une seule échelle (orientation) à gauche\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "base = dat[\"arrays\"].get(\"intensity\", list(dat[\"arrays\"].values())[0])\n",
        "\n",
        "fig = plt.figure(figsize=(15,4))\n",
        "# 1 colonne étroite pour la légende + 4 colonnes pour les images\n",
        "gs = fig.add_gridspec(nrows=1, ncols=5, width_ratios=[0.06, 1, 1, 1, 1], wspace=0.05)\n",
        "\n",
        "# Barre de couleur pour l'orientation θ (en degrés), mappée sur HSV\n",
        "cax = fig.add_subplot(gs[0, 0])\n",
        "sm = mpl.cm.ScalarMappable(cmap=mpl.cm.hsv,\n",
        "                           norm=mpl.colors.Normalize(vmin=-90, vmax=90))\n",
        "cb = fig.colorbar(sm, cax=cax)\n",
        "cb.set_label(\"Orientation θ (deg)\\n(hue)\", fontsize=9)\n",
        "cb.set_ticks([-90, -45, 0, 45, 90])\n",
        "cax.yaxis.tick_left()\n",
        "cax.yaxis.set_label_position('left')\n",
        "\n",
        "# Affiche les 4 premières échelles\n",
        "for i, Hd in enumerate(fused_H[:4]):\n",
        "    ax = fig.add_subplot(gs[0, i+1])\n",
        "    overlay = overlay_hessian_orientation(base, Hd, alpha=0.5)\n",
        "    ax.imshow(overlay)\n",
        "    ax.set_title(f\"Sigma={Hd['sigma']}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94723f52",
      "metadata": {
        "id": "94723f52"
      },
      "source": [
        "## 7–8) Frangi graph and optional triangle-connectivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9563d7a",
      "metadata": {
        "id": "e9563d7a"
      },
      "outputs": [],
      "source": [
        "\n",
        "coords, neighbors, S = build_frangi_similarity_graph(fused_H, beta, c, ctheta, R)\n",
        "D = distances_from_similarity(S)\n",
        "if K==2:\n",
        "    D = triangle_connectivity_graph(coords, D)\n",
        "print(\"Graph nodes:\", D.shape[0], \"non-zeros:\", D.nnz)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3cd5b35",
      "metadata": {
        "id": "b3cd5b35"
      },
      "source": [
        "## 9) Largest connected component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "044da0d6",
      "metadata": {
        "id": "044da0d6"
      },
      "outputs": [],
      "source": [
        "\n",
        "D_cc, idx_nodes = largest_connected_component(D)\n",
        "print(\"Largest CC nodes:\", D_cc.shape[0])\n",
        "sub_coords = coords[idx_nodes]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f46ba111",
      "metadata": {
        "id": "f46ba111"
      },
      "source": [
        "## 10–11) HDBSCAN and cluster display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "304ab6aa",
      "metadata": {
        "id": "304ab6aa"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "import sys\n",
        "\n",
        "# # Increase recursion depth limit to handle potentially deep cluster trees\n",
        "# sys.setrecursionlimit(10000)\n",
        "\n",
        "D_cc64 = D_cc.astype(np.float64, copy=False)\n",
        "\n",
        "labels = hdbscan_from_sparse(\n",
        "    D_cc64,\n",
        "    min_cluster_size=200,\n",
        "    min_samples=1,\n",
        "    allow_single_cluster=True,\n",
        "    expZ=1.0\n",
        ")\n",
        "print(\"Clusters:\", np.unique(labels))\n",
        "show_clusters_on_image(base, sub_coords, labels, figsize=(5,5))\n",
        "\n",
        "\n",
        "# labels = hdbscan_from_sparse(D_cc, min_cluster_size=50, min_samples=5, allow_single_cluster=True, expZ=2.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtration per pixel = min neighbor distance; overlay on image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = D_cc.shape[0]\n",
        "indptr, indices, data = D_cc.indptr, D_cc.indices, D_cc.data\n",
        "\n",
        "filtration = np.full(n, np.inf, dtype=np.float64)\n",
        "for i in range(n):\n",
        "    row_vals = data[indptr[i]:indptr[i+1]]\n",
        "    if row_vals.size > 0:\n",
        "        filtration[i] = float(row_vals.min())\n",
        "\n",
        "# map to image grid (NaN for non-candidate pixels)\n",
        "fmap = np.full(base.shape[:2], np.nan, dtype=np.float32)\n",
        "rr, cc = sub_coords[:,0], sub_coords[:,1]\n",
        "fmap[rr, cc] = filtration.astype(np.float32)\n",
        "\n",
        "# robust display range\n",
        "vmin = np.nanpercentile(fmap, 5)\n",
        "vmax = np.nanpercentile(fmap, 95)\n",
        "masked = np.ma.masked_invalid(fmap)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(base, cmap='gray')\n",
        "im = plt.imshow(masked, cmap='inferno', alpha=0.65, vmin=vmin, vmax=vmax)\n",
        "cb = plt.colorbar(im, fraction=0.046, pad=0.04)\n",
        "cb.set_label(\"Pixel filtration (min edge distance)\", fontsize=9)\n",
        "plt.axis('off')\n",
        "plt.title(\"Filtration overlay\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fqC2T9XUqmBJ"
      },
      "id": "fqC2T9XUqmBJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overlay des crêtes sombres (λ2n >= 0) en transparence, normalisées dans [-1,1]\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) choisir l'échelle par pixel en maximisant |λ2| BRUT\n",
        "e2_raw_stack = np.stack([Hd['e2'] for Hd in fused_H], axis=0)        # [S,H,W]\n",
        "abs_e2_raw_stack = np.abs(e2_raw_stack)\n",
        "best_idx = abs_e2_raw_stack.argmax(axis=0)                           # [H,W]\n",
        "\n",
        "# 2) récupérer, à cette échelle, la λ2 normalisée [-1,1]\n",
        "e2n_stack = np.stack([Hd['e2n'] for Hd in fused_H], axis=0)          # [S,H,W]\n",
        "e2n_best = np.take_along_axis(e2n_stack, best_idx[None, ...], axis=0)[0]\n",
        "\n",
        "# 3) garder les vallées (crêtes sombres) : λ2n >= 0\n",
        "mask = (e2n_best >= 0)\n",
        "\n",
        "# 4) carte à afficher (NaN ailleurs pour transparence), bornée à [0,1]\n",
        "val = np.full_like(e2n_best, np.nan, dtype=np.float32)\n",
        "val[mask] = np.clip(e2n_best[mask], 0.0, 1.0).astype(np.float32)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(base, cmap='gray')\n",
        "im = plt.imshow(val, cmap='magma', alpha=0.65, vmin=0.0, vmax=1.0)\n",
        "cb = plt.colorbar(im, fraction=0.046, pad=0.04)\n",
        "cb.set_label(r\"$\\lambda_2$ normalisée (vallées, $\\lambda_2 > 0$)\", fontsize=9)\n",
        "plt.title(r\"Crêtes sombres : $\\lambda_2 \\in [-1,1]$\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8vgfS76ATVCp"
      },
      "id": "8vgfS76ATVCp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "35bb0505",
      "metadata": {
        "id": "35bb0505"
      },
      "source": [
        "## 12) MST + k-centers -> fault graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a43f0eef",
      "metadata": {
        "id": "a43f0eef"
      },
      "outputs": [],
      "source": [
        "\n",
        "fault_edges_list = []\n",
        "for lab in np.unique(labels):\n",
        "    if lab < 0:\n",
        "        continue\n",
        "    cluster_idx = np.where(labels==lab)[0]\n",
        "    if cluster_idx.size < 3:\n",
        "        continue\n",
        "    mst = mst_on_cluster(D_cc, cluster_idx)\n",
        "    k = max(3, int(cluster_idx.size/100))\n",
        "    centers = kcenters_on_tree(mst, k, objective=\"max\")\n",
        "    Gf = fault_graph_from_mst_and_kcenters(mst, centers, weight_agg=\"mean\")\n",
        "    rows, cols = Gf.nonzero()\n",
        "    for i,j in zip(rows, cols):\n",
        "        if i<j:\n",
        "            w = float(Gf[i,j])\n",
        "            r0,c0 = sub_coords[i]\n",
        "            r1,c1 = sub_coords[j]\n",
        "            fault_edges_list.append([int(r0),int(c0),int(r1),int(c1),w])\n",
        "fault_edges = np.array(fault_edges_list, dtype=np.float32) if len(fault_edges_list)>0 else np.zeros((0,5),dtype=np.float32)\n",
        "print(\"Fault edges:\", fault_edges.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fault_edges"
      ],
      "metadata": {
        "id": "70crbDeHoY0N"
      },
      "id": "70crbDeHoY0N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "232fd370",
      "metadata": {
        "id": "232fd370"
      },
      "source": [
        "## 13) Animation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bf7c449",
      "metadata": {
        "id": "0bf7c449"
      },
      "outputs": [],
      "source": [
        "\n",
        "anim_path = \"fault_growth.gif\"\n",
        "if fault_edges.shape[0] > 0:\n",
        "    animate_fault_growth(dat['arrays']['intensity'], fault_edges, anim_path, steps=25)\n",
        "    from IPython.display import Image, display\n",
        "    display(Image(filename=anim_path))\n",
        "else:\n",
        "    print(\"No fault edges to animate.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5484887",
      "metadata": {
        "id": "a5484887"
      },
      "source": [
        "## 14) Threshold at τ = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa0ca822",
      "metadata": {
        "id": "fa0ca822"
      },
      "outputs": [],
      "source": [
        "\n",
        "tau = 0.3\n",
        "img = dat['arrays']['intensity']\n",
        "overlay = np.dstack([img,img,img]).astype(np.float32)\n",
        "H, W = img.shape[:2]\n",
        "thr_edges = fault_edges[fault_edges[:,-1] <= tau]\n",
        "for e in thr_edges:\n",
        "    r0,c0,r1,c1,w = e\n",
        "    rr = np.linspace(r0, r1, num=int(max(abs(r1-r0),abs(c1-c0))+1)).astype(int)\n",
        "    cc = np.linspace(c0, c1, num=rr.shape[0]).astype(int)\n",
        "    rr = np.clip(rr, 0, H-1); cc = np.clip(cc, 0, W-1)\n",
        "    overlay[rr,cc,0] = 255; overlay[rr,cc,1] = 0; overlay[rr,cc,2] = 0\n",
        "plt.figure(figsize=(5,5)); plt.imshow(overlay.astype(np.uint8)); plt.axis('off'); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87cecd23",
      "metadata": {
        "id": "87cecd23"
      },
      "source": [
        "## 15) Metrics vs GT (Lee skeleton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a5d9cc0",
      "metadata": {
        "id": "0a5d9cc0"
      },
      "outputs": [],
      "source": [
        "\n",
        "mask = np.zeros_like(img, dtype=np.uint8)\n",
        "for e in thr_edges:\n",
        "    r0,c0,r1,c1,w = e\n",
        "    rr = np.linspace(r0, r1, num=int(max(abs(r1-r0),abs(c1-c0))+1)).astype(int)\n",
        "    cc = np.linspace(c0, c1, num=rr.shape[0]).astype(int)\n",
        "    rr = np.clip(rr, 0, img.shape[0]-1); cc = np.clip(cc, 0, img.shape[1]-1)\n",
        "    mask[rr,cc] = 1\n",
        "\n",
        "sk_pred = skeletonize_lee(mask>0)\n",
        "sk_pred = thicken(sk_pred, pixels=6)\n",
        "gt = (dat[\"arrays\"].get(\"label\", np.zeros_like(img)) > 0).astype(np.uint8)\n",
        "sk_gt = skeletonize_lee(gt); sk_gt = thicken(sk_gt, pixels=6)\n",
        "jac = jaccard_index(sk_pred, sk_gt)\n",
        "tvs = tversky_index(sk_pred, sk_gt, alpha=1.0, beta=0.5)\n",
        "wass = wasserstein_distance_skeletons(sk_pred, sk_gt)\n",
        "print(\"Jaccard:\", jac, \"Tversky:\", tvs, \"Wasserstein:\", wass)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,3,1); plt.title(\"GT (thick skel)\"); plt.imshow(sk_gt, cmap='gray'); plt.axis('off')\n",
        "plt.subplot(1,3,2); plt.title(\"Pred (thick skel)\"); plt.imshow(sk_pred, cmap='gray'); plt.axis('off')\n",
        "plt.subplot(1,3,3); plt.title(\"Overlay\"); plt.imshow(sk_gt*255, cmap='Reds', alpha=0.7); plt.imshow(sk_pred*255, cmap='Blues', alpha=0.5); plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}